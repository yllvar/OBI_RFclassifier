{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f3575c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import ccxt\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import logging\n",
    "from logging.handlers import RotatingFileHandler\n",
    "import csv\n",
    "import pickle\n",
    "from dotenv import load_dotenv\n",
    "from finta import TA\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from skopt.space import Real, Integer\n",
    "from scipy import stats\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Constants for CSV Field Names\n",
    "TIMESTAMP = \"Timestamp\"\n",
    "TRADING_SIGNAL = \"Trading Signal\"\n",
    "PROPOSED_ENTRY_PRICE = \"Proposed Entry Price\"\n",
    "ORDER_BOOK_IMBALANCE = \"Order Book Imbalance\"\n",
    "RSI_FIELD = \"RSI\"\n",
    "CSV_FIELD_NAMES = [TIMESTAMP, TRADING_SIGNAL, PROPOSED_ENTRY_PRICE, ORDER_BOOK_IMBALANCE, RSI_FIELD]\n",
    "\n",
    "class RsiTrend:\n",
    "    def __init__(self, symbol, leverage, amount, take_profit_percentage, stop_loss_percentage):\n",
    "        self.symbol = symbol\n",
    "        self.leverage = leverage\n",
    "        self.amount = amount\n",
    "        self.take_profit_percentage = take_profit_percentage\n",
    "        self.stop_loss_percentage = stop_loss_percentage\n",
    "        self.trading_signals_df = self.load_trading_signals_from_csv(\"eth_rsi_trend.csv\")\n",
    "        self.trading_signals = []  \n",
    "        self.logger = logging.getLogger(__name__)\n",
    "        log_file_path = 'eth_rsi_trend.log'\n",
    "        rotating_handler = logging.handlers.RotatingFileHandler(\n",
    "            log_file_path,\n",
    "            maxBytes=1024 * 1024,  # 1 MB per file\n",
    "            backupCount=3  # Keep up to 3 backup log files\n",
    "        )\n",
    "        rotating_handler.setLevel(logging.INFO)\n",
    "        rotating_handler.setFormatter(logging.Formatter('%(asctime)s - %(levelname)s: %(message)s'))\n",
    "        for handler in logging.root.handlers[:]:\n",
    "            logging.root.removeHandler(handler)\n",
    "        # Add the rotating handler to the root logger\n",
    "        logging.getLogger().addHandler(rotating_handler)\n",
    "        \n",
    "        # Initialize the KuCoin Futures exchange instance\n",
    "        self.exchange = ccxt.kucoinfutures({\n",
    "            'apiKey': os.getenv('API_KEY'),\n",
    "            'secret': os.getenv('SECRET_KEY'),\n",
    "            'password': os.getenv('PASSPHRASE'),\n",
    "            'enableRateLimit': True  # Adjust as needed\n",
    "        })\n",
    "        \n",
    "        # Initialize these attributes\n",
    "        self.X_train = None\n",
    "        self.y_train = None\n",
    "        self.X_val = None\n",
    "        self.y_val = None\n",
    "        \n",
    "    def calculate_atr(self, high_prices, low_prices, close_prices, period=14):\n",
    "        try:\n",
    "            if high_prices is None or low_prices is None or close_prices is None:\n",
    "                print(\"Error: One or more data sources are None.\")\n",
    "                return None\n",
    "\n",
    "            # Check if any of the input lists are empty\n",
    "            if not high_prices.all() or not low_prices.all() or not close_prices.all():\n",
    "                #print(\"Error: One or more data sources are empty.\")\n",
    "                return None\n",
    "\n",
    "            # Calculate True Range (TR)\n",
    "            tr = [max(hl, hc, lc) - min(hl, hc, lc) for hl, hc, lc in zip(high_prices, close_prices, low_prices)]\n",
    "\n",
    "            # Calculate the Average True Range (ATR) using a period (e.g., 14)\n",
    "            atr = np.mean(tr[-period:])\n",
    "            return atr\n",
    "\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error calculating ATR: {e}\")\n",
    "            return None \n",
    "\n",
    "    def calculate_rsi(self, close_prices, high_prices, low_prices, atr, period=14):\n",
    "        try:\n",
    "            # Create a DataFrame with required columns\n",
    "            df = pd.DataFrame({'close': close_prices, 'open': close_prices, 'high': high_prices, 'low': low_prices})\n",
    "\n",
    "            # Calculate the RSI using FinTa library\n",
    "            df['rsi'] = TA.RSI(df, period=period)\n",
    "            rsi = df['rsi'].iloc[-1]\n",
    "\n",
    "            return rsi\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error calculating RSI: {e}\")\n",
    "            return None\n",
    "\n",
    "    def calculate_smoothed_imbalance(self, data, alpha=0.1):\n",
    "        try:\n",
    "            #print(\"Input data:\", data)\n",
    "            #print(\"Alpha:\", alpha)\n",
    "\n",
    "            smoothed_data = [data[0]]  # Initialize with the first data value\n",
    "            for i in range(1, len(data)):\n",
    "                smoothed_value = alpha * data[i] + (1 - alpha) * smoothed_data[i - 1]\n",
    "                smoothed_data.append(smoothed_value)\n",
    "                #print(f\"Smoothed value at index {i}: {smoothed_value}\")\n",
    "\n",
    "            #print(\"Smoothed data:\", smoothed_data)\n",
    "            return smoothed_data\n",
    "\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error calculating smoothed imbalance: {e}\")\n",
    "            return None\n",
    "        \n",
    "    def fetch_data_and_preprocess(self, timeframe='15m', limit=1000):\n",
    "        try:\n",
    "            data = []\n",
    "            since = None\n",
    "            \n",
    "            # Fetch order book data outside the loop\n",
    "            bids, asks = self.fetch_order_book(self.symbol)\n",
    "            \n",
    "            while True:\n",
    "                # Fetch OHLCV data\n",
    "                ohlcv = self.exchange.fetch_ohlcv(self.symbol, timeframe, since=since, limit=limit)\n",
    "\n",
    "                if len(ohlcv) == 0:\n",
    "                    break\n",
    "\n",
    "                since = ohlcv[-1][0] + 1\n",
    "                data.extend(list(ohlcv_point) for ohlcv_point in ohlcv)\n",
    "                \n",
    "                # Calculate best bids and asks after fetching all OHLCV data\n",
    "                best_bids, best_asks = self.calculate_best_bids_asks(bids, asks, num_levels=5)\n",
    "\n",
    "                # Extract OHLCV features\n",
    "                ohlcv_features = np.array([d[0:6] for d in data if len(d) == 6])\n",
    "                \n",
    "                # Concatenate OHLCV and order book features\n",
    "                features = np.concatenate((ohlcv_features, best_bids, best_asks), axis=1)\n",
    "                \n",
    "                # Fetch order book data\n",
    "                bids, asks = self.fetch_order_book(self.symbol)\n",
    "                \n",
    "                features = np.array([d[0:6] for d in data if len(d) == 6])  # Use all 6 columns\n",
    "\n",
    "                if np.isnan(features).any():\n",
    "                    mask = ~np.isnan(features).any(axis=1)\n",
    "                    data = [d for d, m in zip(data, mask) if m]\n",
    "                    features = features[mask]\n",
    "\n",
    "                scaler = MinMaxScaler()\n",
    "                scaled_features = scaler.fit_transform(features)\n",
    "\n",
    "                z_scores = np.abs(stats.zscore(scaled_features))\n",
    "                threshold = 3\n",
    "                outlier_mask = (z_scores < threshold).all(axis=1)\n",
    "\n",
    "                data = [d for d, o in zip(data, outlier_mask) if o]\n",
    "                scaled_features = scaled_features[outlier_mask]\n",
    "\n",
    "                # Check if the length of data is sufficient for training\n",
    "                if len(data) < 10:  # Adjust the threshold as needed\n",
    "                    print(\"Insufficient data for training the classifier.\")\n",
    "                    return None, None, None, None\n",
    "\n",
    "                self.save_data_to_csv(data, 'RF_eth.csv')\n",
    "\n",
    "                mean_values = np.mean(scaled_features, axis=0)\n",
    "                std_deviation = np.std(scaled_features, axis=0)\n",
    "                min_values = np.min(scaled_features, axis=0)\n",
    "                max_values = np.max(scaled_features, axis=0)\n",
    "                feature_ranges = max_values - min_values\n",
    "\n",
    "                # Prepare data for classification\n",
    "                X = scaled_features\n",
    "                y = np.array([self.generate_trading_signal(*point[1:]) for point in data])  # Assuming generate_trading_signal returns labels\n",
    "\n",
    "                # Split data into training and testing sets\n",
    "                X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "                # Initialize the Random Forest Classifier\n",
    "                rf_classifier = RandomForestClassifier()\n",
    "\n",
    "                # Train the classifier\n",
    "                rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "                # Evaluate the classifier on the test set\n",
    "                y_pred = rf_classifier.predict(X_test)\n",
    "                print(classification_report(y_test, y_pred))\n",
    "\n",
    "                return data, scaled_features, scaler, rf_classifier\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"An error occurred while fetching and preprocessing data: {e}\")\n",
    "                return None, None, None, None\n",
    "\n",
    "    def train_models(self, features, target):\n",
    "        try:\n",
    "            # Assign values to attributes\n",
    "            self.X_train, self.X_val, self.y_train, self.y_val = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "            random_forest = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "            random_forest.fit(self.X_train, self.y_train)\n",
    "            y_pred = random_forest.predict(self.X_val)\n",
    "            classification_rep = classification_report(self.y_val, y_pred)\n",
    "            print(classification_rep) #print(\"Classification Report for Random Forest Model:\")\n",
    "            print(\"Random Forest Model Training Completed\")  \n",
    "            accuracy_train = random_forest.score(self.X_train, self.y_train) # Print accuracy on training set\n",
    "            print(f\"Accuracy on Training Set: {accuracy_train:.4f}\")   \n",
    "            accuracy_val = random_forest.score(self.X_val, self.y_val) # Print accuracy on validation set\n",
    "            print(f\"Accuracy on Validation Set: {accuracy_val:.4f}\")            \n",
    "            print(\"Random Forest Model:\", random_forest) # Print the models for debugging            \n",
    "            with open('15mincheck15minochlvmodel.pkl', 'wb') as f:\n",
    "                pickle.dump(random_forest, f)\n",
    "            return random_forest\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred while training models: {e}\")\n",
    "            return None\n",
    "\n",
    "    def predict_market_direction(self, data, rf_model, scaler):\n",
    "        try:\n",
    "            features = np.array([d[0:6] for d in data if len(d) == 6])\n",
    "            if not features.any():\n",
    "                print(\"No valid data available for prediction.\")\n",
    "                return None\n",
    "            print(\"Shapes before scaling:\")\n",
    "            print(\"X_train:\", self.X_train.shape)\n",
    "            print(\"X_val:\", self.X_val.shape)\n",
    "            print(\"features:\", features.shape)\n",
    "\n",
    "            scaled_features = scaler.transform(features)\n",
    "\n",
    "            print(\"Shapes after scaling:\")\n",
    "            print(\"X_train:\", self.X_train.shape)\n",
    "            print(\"X_val:\", self.X_val.shape)\n",
    "            print(\"scaled_features:\", scaled_features.shape)\n",
    "\n",
    "            rf_accuracy_train = rf_model.score(self.X_train, self.y_train)\n",
    "            rf_accuracy_val = rf_model.score(self.X_val, self.y_val)\n",
    "            print(f\"Accuracy of Random Forest Model on Training Set: {rf_accuracy_train:.4f}\")\n",
    "            print(f\"Accuracy of Random Forest Model on Validation Set: {rf_accuracy_val:.4f}\")\n",
    "            rf_prediction = rf_model.predict(scaled_features)\n",
    "            print(\"Random Forest Model Prediction on Validation Set:\")\n",
    "            print(rf_prediction)\n",
    "            final_prediction = rf_prediction[-1]\n",
    "            print(\"Final Prediction (0 for Bullish, 1 for Bearish):\")\n",
    "            print(final_prediction)\n",
    "            return final_prediction\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred while predicting market direction: {e}\")\n",
    "            return None\n",
    "\n",
    "    def fetch_ohlcv_and_analyze_order_book(self, symbol, depth=100, max_retries=3):\n",
    "        retries = 0\n",
    "        # Initialize a list to store historical imbalance percentages\n",
    "        historical_imbalance_percentage = []\n",
    "\n",
    "        rsi = None\n",
    "        current_imbalance_percentage = None\n",
    "        close_prices = None\n",
    "        high_prices = None\n",
    "        low_prices = None\n",
    "        bids = None\n",
    "        asks = None\n",
    "\n",
    "        while retries < max_retries:\n",
    "            try:\n",
    "                # Use time module to get the current timestamp\n",
    "                current_time = int(time.time() * 1000)  # Convert seconds to milliseconds\n",
    "\n",
    "                # Fetch OHLCV data for ATR and TR calculation\n",
    "                ohlcv_data = self.exchange.fetch_ohlcv(symbol, '15m')  # Adjust timeframe as needed\n",
    "                close_prices = np.array([item[4] for item in ohlcv_data])\n",
    "                high_prices = np.array([item[2] for item in ohlcv_data])\n",
    "                low_prices = np.array([item[3] for item in ohlcv_data])\n",
    "\n",
    "                # Fetch volume data\n",
    "                volume_data = np.array([item[5] for item in ohlcv_data])\n",
    "\n",
    "                # Calculate True Range (TR)\n",
    "                tr = [max(hl, hc, lc) - min(hl, hc, lc) for hl, hc, lc in zip(high_prices, close_prices, low_prices)]\n",
    "\n",
    "                # Calculate Average True Range (ATR) using a period (e.g., 14)\n",
    "                atr = np.mean(tr[-14:])\n",
    "\n",
    "                rsi = self.calculate_rsi(close_prices, high_prices, low_prices, atr)\n",
    "\n",
    "                # Fetch the order book for the specified symbol and depth\n",
    "                order_book = self.exchange.fetch_order_book(symbol, limit=20)\n",
    "                bids = order_book['bids']\n",
    "                asks = order_book['asks']\n",
    "\n",
    "                # Extract bid prices and quantities\n",
    "                bid_prices = [bid[0] for bid in bids]\n",
    "                bid_quantities = [bid[1] for bid in bids]\n",
    "\n",
    "                # Extract ask prices and quantities\n",
    "                ask_prices = [ask[0] for ask in asks]\n",
    "                ask_quantities = [ask[1] for ask in asks]\n",
    "\n",
    "                # Calculate the total volume of bids and asks\n",
    "                total_bids_volume = sum(bid[1] for bid in bids)\n",
    "                total_asks_volume = sum(ask[1] for ask in asks)\n",
    "\n",
    "                # Calculate the current order book imbalance percentage\n",
    "                current_imbalance_percentage = (\n",
    "                    (total_bids_volume - total_asks_volume) / (total_bids_volume + total_asks_volume)\n",
    "                ) * 100\n",
    "\n",
    "                # Log order book analysis results\n",
    "                self.logger.info(\n",
    "                    f\"Order Book Analysis for {symbol} - Imbalance: {current_imbalance_percentage:.2f}% - RSI: {rsi:.2f} - \"\n",
    "                    f\"Current Market Price: {close_prices[-1]:.8f}\"  # Print the current market price\n",
    "                )\n",
    "\n",
    "                # Print order book analysis results directly to the console\n",
    "                print(\n",
    "                    f\"Order Book Analysis for {symbol} - Imbalance: {current_imbalance_percentage:.2f}% - RSI: {rsi:.2f} - \"\n",
    "                    f\"Current Market Price: {close_prices[-1]:.8f}\"  # Print the current market price\n",
    "                )\n",
    "\n",
    "                # Append the current imbalance percentage to the historical list\n",
    "                historical_imbalance_percentage.append(current_imbalance_percentage)\n",
    "\n",
    "                # Calculate smoothed order book imbalance using EMA\n",
    "                smoothed_imbalance = self.calculate_smoothed_imbalance(historical_imbalance_percentage)\n",
    "\n",
    "                # Generate trading signal and proposed entry price based on RSI and order book imbalance\n",
    "                trading_signal, proposed_entry_price, take_profit_price, stop_loss_price = self.generate_trading_signal(\n",
    "                    rsi,\n",
    "                    current_imbalance_percentage,\n",
    "                    close_prices,\n",
    "                    high_prices,\n",
    "                    low_prices,\n",
    "                    bids,\n",
    "                    asks\n",
    "                )\n",
    "\n",
    "                print(\"Trading Signal:\", trading_signal)\n",
    "                if proposed_entry_price:\n",
    "                    print(\"Proposed Entry Price:\", proposed_entry_price)\n",
    "                    print(\"Take Profit Price:\", take_profit_price)\n",
    "                    print(\"Stop Loss Price:\", stop_loss_price)\n",
    "\n",
    "                # Exit the retry loop if data is successfully fetched and analyzed\n",
    "                break\n",
    "\n",
    "            except Exception as e:\n",
    "                retries += 1\n",
    "                self.logger.error(\n",
    "                    f\"Error fetching or analyzing order book: {e}\" if e is not None else \"Unknown error occurred.\",\n",
    "                    exc_info=True  # Include exception information in the log\n",
    "                )\n",
    "                self.logger.info(f\"Retrying... ({retries}/{max_retries})\")\n",
    "                time.sleep(10)  # Wait for 10 seconds before retrying\n",
    "\n",
    "        # Return the calculated values\n",
    "        return rsi, current_imbalance_percentage, close_prices, high_prices, low_prices, bids, asks\n",
    "    \n",
    "    def save_trading_signals_to_csv(self):\n",
    "        try:\n",
    "            file_path = \"eth_rsi_trend.csv\"\n",
    "            # Check if the file already exists\n",
    "            file_exists = os.path.exists(file_path)\n",
    "            # Open the file in append mode\n",
    "            with open(file_path, \"a\", newline='') as csv_file:\n",
    "                csv_writer = csv.DictWriter(csv_file, fieldnames=CSV_FIELD_NAMES)\n",
    "                # Write header only if the file is newly created\n",
    "                if not file_exists:\n",
    "                    print(\"Writing header to CSV file...\")\n",
    "                    csv_writer.writeheader()\n",
    "                # Write the data to the CSV file\n",
    "                for signal in self.trading_signals_df.to_dict(orient='records'):\n",
    "                    #print(f\"Writing signal to CSV: {signal}\")\n",
    "                    csv_writer.writerow({\n",
    "                        TIMESTAMP: signal[TIMESTAMP],\n",
    "                        TRADING_SIGNAL: signal[TRADING_SIGNAL],\n",
    "                        PROPOSED_ENTRY_PRICE: signal[PROPOSED_ENTRY_PRICE],\n",
    "                        ORDER_BOOK_IMBALANCE: signal[ORDER_BOOK_IMBALANCE],\n",
    "                        RSI_FIELD: signal[RSI_FIELD]\n",
    "                    })\n",
    "            print(\"CSV file saved successfully.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error saving trading signals to CSV: {e}\")\n",
    "                \n",
    "    def load_trading_signals_from_csv(self, file_path):\n",
    "        try:\n",
    "            #print(\"Reading CSV file:\", file_path)\n",
    "            historical_signals = pd.read_csv(file_path, parse_dates=[\"Timestamp\"], na_values=['nan', 'NaN'], dtype={'Trading Signal': str})\n",
    "            # Print unique values in the \"Trading Signal\" column\n",
    "            #print(\"Unique values in 'Trading Signal' column:\", historical_signals[\"Trading Signal\"].unique())\n",
    "            # Replace NaN values in 'Trading Signal' column with 'No Entry'\n",
    "            #print(\"Replacing NaN values in 'Trading Signal' column with 'No Entry'...\")\n",
    "            historical_signals.fillna(value={'Trading Signal': 'No Entry'}, inplace=True)\n",
    "            with open(file_path, \"r\", newline='') as csv_file:\n",
    "                csv_reader = csv.DictReader(csv_file)\n",
    "                # Check if the required columns exist in the CSV file\n",
    "                required_columns = {\"Timestamp\", \"Trading Signal\", \"Proposed Entry Price\", \"Order Book Imbalance\", \"RSI\"}\n",
    "                if not required_columns.issubset(csv_reader.fieldnames):\n",
    "                    #print(f\"Error: The CSV file is missing one or more required columns. Actual columns: {csv_reader.fieldnames}\")\n",
    "                    return historical_signals\n",
    "                signals_list = []  # Create a list to store signals\n",
    "                for row in csv_reader:\n",
    "                    timestamp_str = row[\"Timestamp\"]\n",
    "                    timestamp = pd.to_datetime(timestamp_str) if timestamp_str != 'NaT' else pd.NaT\n",
    "                    trading_signal = row[\"Trading Signal\"]\n",
    "                    proposed_entry_price = float(row[\"Proposed Entry Price\"]) if row[\"Proposed Entry Price\"] else None\n",
    "                    order_book_imbalance = float(row[\"Order Book Imbalance\"]) if row[\"Order Book Imbalance\"] else None\n",
    "                    rsi = float(row[\"RSI\"]) if row[\"RSI\"] else None\n",
    "                    signal = {\n",
    "                        \"timestamp\": timestamp,\n",
    "                        \"trading_signal\": trading_signal,\n",
    "                        \"proposed_entry_price\": proposed_entry_price,\n",
    "                        \"order_book_imbalance\": order_book_imbalance,\n",
    "                        \"rsi\": rsi\n",
    "                    }\n",
    "                    signals_list.append(signal)  # Append each signal to the list\n",
    "                # Print DataFrame columns here\n",
    "                #print(\"Columns in historical_signals DataFrame:\", historical_signals.columns)\n",
    "                historical_signals = pd.DataFrame(columns=[\"Timestamp\", \"Trading Signal\", \"Proposed Entry Price\", \"Order Book Imbalance\", \"RSI\"])\n",
    "\n",
    "        except FileNotFoundError:\n",
    "            # The file may not exist initially, which is fine\n",
    "            print(\"CSV file not found. Returning empty DataFrame.\")\n",
    "            historical_signals = pd.DataFrame(columns=CSV_FIELD_NAMES)\n",
    "            return historical_signals\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading trading signals from CSV: {e}\")\n",
    "            return None\n",
    "\n",
    "        return historical_signals\n",
    "    \n",
    "    def save_data_to_csv(self, data, filename):\n",
    "        header = [\"timestamp\", \"open\", \"high\", \"low\", \"close\"]\n",
    "        with open(filename, 'a', newline='') as csv_file:\n",
    "            writer = csv.writer(csv_file)\n",
    "            if csv_file.tell() == 0:\n",
    "                writer.writerow(header)\n",
    "            for d in data:\n",
    "                writer.writerow(d)\n",
    "    \n",
    "    def calculate_take_profit_and_stop_loss(self, entry_price, leverage, take_profit_percentage, stop_loss_percentage):\n",
    "        # Calculate the leverage-adjusted entry price\n",
    "        leverage_adjusted_entry_price = entry_price / leverage\n",
    "\n",
    "        # Calculate take profit and stop loss prices based on the leverage-adjusted entry price\n",
    "        take_profit_price = round(entry_price * (1 + TAKE_PROFIT_PERCENTAGE / 100), 8)\n",
    "        stop_loss_price = round(entry_price * (1 - STOP_LOSS_PERCENTAGE / 100), 8)\n",
    "\n",
    "        return take_profit_price, stop_loss_price\n",
    "\n",
    "    def generate_trading_signal(self, rsi, imbalance_percentage, close_prices, high_prices, low_prices, bids, asks):\n",
    "        try:\n",
    "            self.logger.debug(\"Starting generate_trading_signal...\")\n",
    "\n",
    "            if imbalance_percentage >= 20:  # Positive imbalance condition\n",
    "                self.logger.debug(\"Positive imbalance condition detected.\")\n",
    "                # Check for bullish RSI divergence (oversold RSI)\n",
    "                if rsi < 28:\n",
    "                    print(\"Bullish RSI divergence detected.\")\n",
    "                    proposed_entry_price = bids[0][0]\n",
    "\n",
    "                    # Calculate take profit and stop loss prices\n",
    "                    take_profit_price, stop_loss_price = self.calculate_take_profit_and_stop_loss(\n",
    "                        proposed_entry_price,\n",
    "                        self.leverage,\n",
    "                        self.take_profit_percentage,\n",
    "                        self.stop_loss_percentage\n",
    "                    )\n",
    "\n",
    "                    print(\"Validated Bullish Divergence (Long)\")\n",
    "                    return \"Validated Bullish Divergence (Long)\", proposed_entry_price, take_profit_price, stop_loss_price\n",
    "                else:\n",
    "                    #print(\"No bullish RSI divergence.\")\n",
    "                    return \"No Entry\", None, None, None\n",
    "            elif imbalance_percentage <= -20:  # Negative imbalance condition\n",
    "                self.logger.debug(\"Negative imbalance condition detected.\")\n",
    "                # Check for bearish RSI divergence (overbought RSI)\n",
    "                if rsi > 72:\n",
    "                    print(\"Bearish RSI divergence detected.\")\n",
    "                    proposed_entry_price = asks[0][0]\n",
    "\n",
    "                    # Calculate take profit and stop loss prices\n",
    "                    take_profit_price, stop_loss_price = self.calculate_take_profit_and_stop_loss(\n",
    "                        proposed_entry_price,\n",
    "                        self.leverage,\n",
    "                        self.take_profit_percentage,\n",
    "                        self.stop_loss_percentage\n",
    "                    )\n",
    "\n",
    "                    print(\"Validated Bearish Divergence (Short)\")\n",
    "                    return \"Validated Bearish Divergence (Short)\", proposed_entry_price, take_profit_price, stop_loss_price\n",
    "                else:\n",
    "                    #print(\"No bearish RSI divergence.\")\n",
    "                    return \"No Entry\", None, None, None\n",
    "\n",
    "            self.logger.debug(\"Exiting generate_trading_signal...\")\n",
    "\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error in generate_trading_signal: {e}\")\n",
    "            self.logger.debug(\"Error in generate_trading_signal:\", e)\n",
    "            return \"No Entry\", None, None, None\n",
    "    \n",
    "    def execute_order_book_analysis(self):\n",
    "        while True:\n",
    "            try:\n",
    "                self.logger.info(\"Fetching OHLCV data and analyzing order book...\")\n",
    "                rsi, imbalance_percentage, close_prices, high_prices, low_prices, bids, asks = self.fetch_ohlcv_and_analyze_order_book(symbol_to_analyze)\n",
    "\n",
    "                # Generate trading signal and proposed entry price based on RSI and order book imbalance\n",
    "                trading_signal, proposed_entry_price, take_profit_price, stop_loss_price = self.generate_trading_signal(\n",
    "                    rsi,\n",
    "                    imbalance_percentage,\n",
    "                    close_prices,\n",
    "                    high_prices,\n",
    "                    low_prices,\n",
    "                    bids,  # Pass 'bids' explicitly\n",
    "                    asks  # Pass 'asks' explicitly\n",
    "                )\n",
    "\n",
    "                # Get the current timestamp\n",
    "                timestamp = int(time.time() * 1000)\n",
    "                timestamp_datetime = datetime.fromtimestamp(timestamp / 1000.0)\n",
    "\n",
    "                # Create a new signal dictionary\n",
    "                new_signal = {\n",
    "                    TIMESTAMP: timestamp_datetime,\n",
    "                    TRADING_SIGNAL: trading_signal,\n",
    "                    PROPOSED_ENTRY_PRICE: proposed_entry_price,\n",
    "                    ORDER_BOOK_IMBALANCE: imbalance_percentage,  # Include order book imbalance\n",
    "                    RSI_FIELD: rsi  # Include RSI\n",
    "                }\n",
    "\n",
    "                # Preprocess data and train Random Forest Classifier\n",
    "                data, scaled_features, scaler, rf_classifier = self.fetch_data_and_preprocess()\n",
    "\n",
    "                # Predict using the trained classifier\n",
    "                prediction = rf_classifier.predict(scaled_features[-1].reshape(1, -1))[0]\n",
    "\n",
    "                # Map the prediction to a trading signal\n",
    "                if prediction == 1:\n",
    "                    prediction_signal = \"Buy\"\n",
    "                else:\n",
    "                    prediction_signal = \"Sell\"\n",
    "\n",
    "                # Update the trading signal based on the classifier prediction\n",
    "                if prediction_signal != \"No Entry\":\n",
    "                    trading_signal = prediction_signal\n",
    "                    \n",
    "                # Print the relevant information\n",
    "                self.logger.debug(f\"Timestamp: {timestamp_datetime}\")\n",
    "\n",
    "                if proposed_entry_price:\n",
    "                    print(f\"Proposed Entry Price: {proposed_entry_price}\")\n",
    "\n",
    "                # Append the new signal to trading_signals_df\n",
    "                self.trading_signals_df = pd.concat([self.trading_signals_df, pd.DataFrame([new_signal])], ignore_index=True)\n",
    "\n",
    "                # Call the saving function to update the CSV file\n",
    "                self.save_trading_signals_to_csv()\n",
    "\n",
    "                if trading_signal != \"No Entry\" and proposed_entry_price:\n",
    "                    # Create a limit order based on the signal\n",
    "                    if trading_signal.startswith(\"Validated Bullish\"):\n",
    "                        # Pass the desired take profit and stop loss percentages to the order creation function\n",
    "                        self.create_order_with_percentage_levels('buy', proposed_entry_price)\n",
    "                    elif trading_signal.startswith(\"Validated Bearish\"):\n",
    "                        # Pass the desired take profit and stop loss percentages to the order creation function\n",
    "                        self.create_order_with_percentage_levels('sell', proposed_entry_price)\n",
    "\n",
    "            except Exception as e:\n",
    "                self.logger.error(f\"Error in main loop: {e}\")\n",
    "                print(\"Exiting execute_order_book_analysis...\")\n",
    "                print(\"=\" * 50)\n",
    "                print(\"Environment variables loaded successfully.\")\n",
    "                logging.basicConfig(filename='eth_rsi_trend.log', level=logging.DEBUG, format='%(asctime)s - %(levelname)s: %(message)s')\n",
    "                print(\"Logging initiated successfully.\")\n",
    "\n",
    "                time.sleep(20)\n",
    "\n",
    "symbol_to_analyze = 'ETH/USDT:USDT'\n",
    "leverage = 10\n",
    "amount = 10\n",
    "TAKE_PROFIT_PERCENTAGE = 1.35\n",
    "STOP_LOSS_PERCENTAGE = 1.35\n",
    "\n",
    "analyzer = RsiTrend(symbol_to_analyze, leverage, amount, TAKE_PROFIT_PERCENTAGE, STOP_LOSS_PERCENTAGE)\n",
    "historical_trading_signals = analyzer.load_trading_signals_from_csv(\"eth_rsi_trend.csv\")\n",
    "trading_signals = historical_trading_signals if not historical_trading_signals.empty else []\n",
    "analyzer.execute_order_book_analysis()\n",
    "analyzer.save_trading_signals_to_csv()\n",
    "\n",
    "for handler in logging.root.handlers[:]:\n",
    "    logging.root.removeHandler(handler)\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
